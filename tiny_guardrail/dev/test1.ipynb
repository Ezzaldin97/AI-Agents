{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")\n",
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### using hugging face API service to access Open Source Models..........\n",
    "client = InferenceClient(api_key=os.getenv('HF_TOKEN'))\n",
    "\n",
    "messages = [\n",
    "\t{ \"role\": \"user\", \"content\": \"hi\" },\n",
    "\t{ \"role\": \"assistant\", \"content\": \"can you write a function remove curse words from a input text.\" }\n",
    "]\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=os.getenv('HF_MODEL'), \n",
    "\tmessages=messages, \n",
    "\ttemperature=0.5,\n",
    "\tmax_tokens=2048,\n",
    "\ttop_p=0.7,\n",
    "\t#stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Below is a Python function that removes curse words from an input text. This function uses a predefined list of curse words and removes any occurrence of these words from the input text. You can customize the list of curse words as needed.\n",
      "\n",
      "```python\n",
      "def remove_curse_words(input_text, curse_words):\n",
      "    # Convert the input text to lowercase to make the comparison case-insensitive\n",
      "    input_text_lower = input_text.lower()\n",
      "    \n",
      "    # Iterate over each curse word and replace it with an empty string\n",
      "    for word in curse_words:\n",
      "        input_text_lower = input_text_lower.replace(word, '')\n",
      "    \n",
      "    # Reconstruct the output text while preserving the original case\n",
      "    output_text = ''\n",
      "    curse_words_set = set(curse_words)\n",
      "    for word in input_text.split():\n",
      "        if word.lower() not in curse_words_set:\n",
      "            output_text += word + ' '\n",
      "    \n",
      "    # Remove the trailing space\n",
      "    output_text = output_text.strip()\n",
      "    \n",
      "    return output_text\n",
      "\n",
      "# Example usage\n",
      "curse_words = ['badword1', 'badword2', 'badword3']\n",
      "input_text = \"This is a sample text with badword1 and some other badword2 words.\"\n",
      "clean_text = remove_curse_words(input_text, curse_words)\n",
      "print(clean_text)\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **Lowercase Conversion**: The input text is converted to lowercase to ensure that the comparison is case-insensitive.\n",
      "2. **Replacement**: Each curse word in the list is replaced with an empty string in the lowercase version of the input text.\n",
      "3. **Reconstruction**: The output text is reconstructed by iterating over the original input text and excluding any words that are in the list of curse words.\n",
      "4. **Output**: The final output text is returned after removing any trailing spaces.\n",
      "\n",
      "### Customization:\n",
      "- You can add or remove words from the `curse_words` list to customize the function to your needs.\n",
      "- The function currently removes the entire word if it matches a curse word. If you want to replace the curse words with a placeholder (e.g., `****`), you can modify the replacement step accordingly.\n",
      "\n",
      "Let me know if you need any further assistance!\n"
     ]
    }
   ],
   "source": [
    "print(stream.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, LLM\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "from crewai.utilities.exceptions.context_window_exceeding_exception import (\n",
    "    LLMContextLengthExceededException,\n",
    ")\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HfLLM(LLM):\n",
    "    \"\"\"Hugging Face Large Language Model (LLM)\"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            model: str, \n",
    "            api_key: str, \n",
    "            temperature: float, \n",
    "            max_tokens: int, \n",
    "            top_p: float\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "            top_p=top_p,\n",
    "            api_key=api_key,\n",
    "        )\n",
    "    \n",
    "    def get_context_window_size(self) -> int:\n",
    "        # Only using 75% of the context window size to avoid cutting the message in the middle\n",
    "        return int(128_000 * 0.75)\n",
    "    \n",
    "    def call(\n",
    "        self, \n",
    "        messages: List[Dict[str, str]], \n",
    "        callbacks: List[Any] = []\n",
    "    ) -> str:\n",
    "        #### using hugging face API service to access Open Source Models..........\n",
    "        try:\n",
    "            client = InferenceClient(api_key=self.api_key)\n",
    "            output = client.chat.completions.create(\n",
    "                model=self.model, \n",
    "\t            messages=messages, \n",
    "\t            temperature=self.temperature,\n",
    "\t            max_tokens=self.max_tokens,\n",
    "\t            top_p=self.top_p,\n",
    "            )\n",
    "            return output.choices[0].message.content\n",
    "        except Exception as e:\n",
    "                if not LLMContextLengthExceededException(\n",
    "                    str(e)\n",
    "                )._is_context_limit_error(str(e)):\n",
    "                    logging.error(f\"LLM call failed: {str(e)}\")\n",
    "\n",
    "                raise  # Re-raise the exception after logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_llm = HfLLM(\n",
    "    model=\"Qwen/Qwen2.5-72B-Instruct\", \n",
    "\ttemperature=0.5,\n",
    "\tmax_tokens=2048,\n",
    "\ttop_p=0.7,\n",
    "    api_key=os.getenv('HF_TOKEN')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = hf_llm.call(messages = [\n",
    "\t{ \"role\": \"user\", \"content\": \"hi\" },\n",
    "\t{ \"role\": \"assistant\", \"content\": \"how knight moves in chess.\" }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! It seems like you might have been interested in how a knight moves in chess, but your message got a bit mixed up. Let me explain:\n",
      "\n",
      "In chess, the knight moves in an \"L\" shape. This means it can move two squares in one direction (horizontally or vertically) and then one square perpendicular to that direction, or one square in one direction and then two squares perpendicular to that direction. The knight is the only piece that can \"jump\" over other pieces, making it unique and very versatile.\n",
      "\n",
      "Here are a few examples of how a knight can move from a central square (e.g., d4):\n",
      "\n",
      "- From d4, the knight can move to b3, b5, c2, c6, e2, e6, f3, or f5.\n",
      "\n",
      "Would you like to know more about chess or the knight's movements?\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.HfLLM"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(hf_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "crewai_hf_llm = LLM(\n",
    "    model=f\"{os.getenv('REMOTE_PROVIDER')}/{os.getenv('HF_MODEL')}\", \n",
    "    api_key=os.getenv('HF_TOKEN')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It seems like there might be a bit of a mix-up in your question. In chess, the piece you might be referring to is the \"rook,\" not \"rock.\" The rook is a powerful piece that moves horizontally or vertically, any number of squares, across the board. Here are the key points about the rook\\'s movement:\\n\\n1. **Horizontal Movement:** The rook can move any number of squares to the left or right, as long as there are no pieces blocking its'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crewai_hf_llm.call(\n",
    "    messages=[\n",
    "\t{ \"role\": \"user\", \"content\": \"hi\" },\n",
    "\t{ \"role\": \"assistant\", \"content\": \"how rock moves in chess.\" }\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai_tools import CSVSearchTool, FileReadTool, DirectoryReadTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\agents\\database_agent\\.venv\\lib\\site-packages\\embedchain\\embedder\\ollama.py:27: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(model=self.config.model, base_url=config.base_url)\n"
     ]
    }
   ],
   "source": [
    "csv_search = CSVSearchTool(\n",
    "    csv=os.path.join(os.pardir, os.getenv('TEMP_FILES_PATH'), 'Iris.csv'),\n",
    "    config = dict(\n",
    "        llm=dict(\n",
    "            provider=\"ollama\",\n",
    "            config=dict(\n",
    "                model=\"llama3.2:1b\",\n",
    "            )\n",
    "        ),\n",
    "        embedder=dict(\n",
    "            provider=\"ollama\",\n",
    "            config=dict(\n",
    "                model=\"nomic-embed-text:latest\",\n",
    "            )\n",
    "        ),\n",
    "        vectordb=dict(\n",
    "            provider=\"chroma\",\n",
    "            config=dict(\n",
    "                dir=\"../assets/data/databases\",\n",
    "                collection_name=\"iris\"\n",
    "            ),\n",
    "        ),    \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Content:\n",
      "Id: 100, SepalLengthCm: 5.7, SepalWidthCm: 2.8, PetalLengthCm: 4.1, PetalWidthCm: 1.3, Species: Iris-versicolor\n",
      "\n",
      "Id: 80, SepalLengthCm: 5.7, SepalWidthCm: 2.6, PetalLengthCm: 3.5, PetalWidthCm: 1.0, Species: Iris-versicolor\n",
      "\n",
      "Id: 68, SepalLengthCm: 5.8, SepalWidthCm: 2.7, PetalLengthCm: 4.1, PetalWidthCm: 1.0, Species: Iris-versicolor\n"
     ]
    }
   ],
   "source": [
    "test_results = csv_search._run(search_query=\"what's the average value of SepalLengthCm for Iris-versicolor?\")\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presidio imports\n",
    "from presidio_analyzer import AnalyzerEngine\n",
    "from presidio_anonymizer import AnonymizerEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-23 23:25:51,617 - 2308 - nlp_engine_provider.py-nlp_engine_provider:118 - WARNING: configuration file d:\\agents\\database_agent\\.venv\\lib\\site-packages\\conf\\default.yaml not found.  Using default config: {'nlp_engine_name': 'spacy', 'models': [{'lang_code': 'en', 'model_name': 'en_core_web_lg'}]}.\n",
      "2024-11-23 23:25:51,620 - 2308 - nlp_engine_provider.py-nlp_engine_provider:127 - WARNING: configuration file is missing 'ner_model_configuration'. Using default\n",
      "2024-11-23 23:25:51,623 - 2308 - ner_model_configuration.py-ner_model_configuration:78 - WARNING: model_to_presidio_entity_mapping is missing from configuration, using default\n",
      "2024-11-23 23:25:51,626 - 2308 - ner_model_configuration.py-ner_model_configuration:84 - WARNING: low_score_entity_names is missing from configuration, using default\n",
      "2024-11-23 23:25:51,631 - 2308 - ner_model_configuration.py-ner_model_configuration:89 - WARNING: labels_to_ignore is missing from configuration, using default\n"
     ]
    }
   ],
   "source": [
    "presidio_analyzer = AnalyzerEngine()\n",
    "presidio_anonymizer= AnonymizerEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's analyze the text\n",
    "text = \"can you tell me what orders i've placed in the last 3 months? my name is Hank Tate and my phone number is 555-123-4567\"\n",
    "analysis = presidio_analyzer.analyze(text, language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[type: DATE_TIME, start: 43, end: 60, score: 0.85,\n",
       " type: PERSON, start: 73, end: 82, score: 0.85,\n",
       " type: PHONE_NUMBER, start: 106, end: 118, score: 0.75]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: can you tell me what orders i've placed in <DATE_TIME>? my name is <PERSON> and my phone number is <PHONE_NUMBER>\n",
      "items:\n",
      "[\n",
      "    {'start': 99, 'end': 113, 'entity_type': 'PHONE_NUMBER', 'text': '<PHONE_NUMBER>', 'operator': 'replace'},\n",
      "    {'start': 67, 'end': 75, 'entity_type': 'PERSON', 'text': '<PERSON>', 'operator': 'replace'},\n",
      "    {'start': 43, 'end': 54, 'entity_type': 'DATE_TIME', 'text': '<DATE_TIME>', 'operator': 'replace'}\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(presidio_anonymizer.anonymize(text=text, analyzer_results=analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai.tools import BaseTool\n",
    "from typing import Type\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIIRemovalInput(BaseModel):\n",
    "    \"\"\"Input schema for PII Removal.\"\"\"\n",
    "    text: str = Field(..., description=\"input text.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIIRemovalTool(BaseTool):\n",
    "    name: str = \"PII Removal\"\n",
    "    description: str = (\n",
    "        \"Remove PII From Input Text to prevent PII Leakage.\"\n",
    "    )\n",
    "    args_schema: Type[BaseModel] = PIIRemovalInput\n",
    "\n",
    "    def replace_pii(self, text: str):\n",
    "        # Replace PII with a placeholder\n",
    "        analyzer = AnalyzerEngine()\n",
    "        anonymizer = AnonymizerEngine()\n",
    "        analysis = analyzer.analyze(text, language='en')\n",
    "        res = anonymizer.anonymize(text=text, analyzer_results=analysis)\n",
    "        return res.text\n",
    "\n",
    "    def _run(self, text: str) -> str:\n",
    "        # Implementation goes here\n",
    "        return self.replace_pii(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pii_tool = PIIRemovalTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-23 23:27:12,983 - 2308 - nlp_engine_provider.py-nlp_engine_provider:118 - WARNING: configuration file d:\\agents\\database_agent\\.venv\\lib\\site-packages\\conf\\default.yaml not found.  Using default config: {'nlp_engine_name': 'spacy', 'models': [{'lang_code': 'en', 'model_name': 'en_core_web_lg'}]}.\n",
      "2024-11-23 23:27:12,986 - 2308 - nlp_engine_provider.py-nlp_engine_provider:127 - WARNING: configuration file is missing 'ner_model_configuration'. Using default\n",
      "2024-11-23 23:27:12,990 - 2308 - ner_model_configuration.py-ner_model_configuration:78 - WARNING: model_to_presidio_entity_mapping is missing from configuration, using default\n",
      "2024-11-23 23:27:12,993 - 2308 - ner_model_configuration.py-ner_model_configuration:84 - WARNING: low_score_entity_names is missing from configuration, using default\n",
      "2024-11-23 23:27:12,995 - 2308 - ner_model_configuration.py-ner_model_configuration:89 - WARNING: labels_to_ignore is missing from configuration, using default\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"can you tell me what orders i've placed in <DATE_TIME>? my name is <PERSON> and my phone number is <PHONE_NUMBER>\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pii_tool._run(text=\"can you tell me what orders i've placed in the last 3 months? my name is Hank Tate and my phone number is 555-123-4567\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from better_profanity import profanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go to ****'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censored_text = profanity.censor(\n",
    "    \"Go to hell\",\n",
    ")\n",
    "censored_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BadWordsRemovalInput(BaseModel):\n",
    "    \"\"\"Input schema for PII Removal.\"\"\"\n",
    "    text: str = Field(..., description=\"input text.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BadWordsRemovalTool(BaseTool):\n",
    "    name: str = \"Bad Word Removal\"\n",
    "    description: str = (\n",
    "        \"Remove Bad Words From Input Text .\"\n",
    "    )\n",
    "    args_schema: Type[BaseModel] = BadWordsRemovalInput\n",
    "\n",
    "    def _run(self, text: str) -> str:\n",
    "        # Implementation goes here\n",
    "        return profanity.censor(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we are in deep ****'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_words = BadWordsRemovalTool()\n",
    "bad_words._run(\"we are in deep shit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-23 23:28:39,083 - 2308 - llm.py-llm:178 - ERROR: Failed to get supported params: argument of type 'NoneType' is not iterable\n"
     ]
    }
   ],
   "source": [
    "csv_parser = Agent(\n",
    "    role=\"CSV Reader\",\n",
    "    goal=\"Extract Data From Retrieved CSV Results\",\n",
    "    backstory=(\n",
    "        \"From the Retrieved Results, Your role is to Understand the Asked Question\"\n",
    "        \"answer based on the Results.\"\n",
    "    ),\n",
    "    llm=LLM(\n",
    "        model=os.getenv('MODEL'),\n",
    "        base_url=os.getenv('API_BASE'),\n",
    "    ),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_parser_tool = Task(\n",
    "    tools = [csv_search],\n",
    "    agent = csv_parser,\n",
    "    description = (\n",
    "        \"Using the Search Results, Answer the given Question: {search_query}\"\n",
    "        \"or give some code in case it needs some analysis to extract the result.\"\n",
    "    ),\n",
    "    expected_output = (\n",
    "        \"The Result Should describe how to get the result in case of code\"\n",
    "        \"or should show the output directly if it could be extracted.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pii_guardrail = Agent(\n",
    "    role = \"PII Guardrail\",\n",
    "    goal = (\n",
    "        \"Your role is to read text carefully\"\n",
    "        \"and remove PII data from content\"\n",
    "        \"then return the content without PII Data\"\n",
    "    ),\n",
    "    backstory = (\n",
    "        \"You are a PII Guardrail, your job is to protect the PII data \"\n",
    "        \"from being exposed.\" \n",
    "    ),\n",
    "    llm=crewai_hf_llm,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_words_guardrail = Agent(\n",
    "    role = \"Bad Words Guardrail\",\n",
    "    goal = (\n",
    "        \"Your role is to read text carefully\"\n",
    "        \"and remove Bad and Curse words from content\"\n",
    "        \"then return the content without Bad Words\"\n",
    "    ),\n",
    "    backstory = (\n",
    "        \"You are a guardrail that protects the text from bad words. \"\n",
    "    ),\n",
    "    llm=crewai_hf_llm,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardrail = Agent(\n",
    "    role = \"Guardrail\",\n",
    "    goal = (\n",
    "        \"Your role is to read text carefully\"\n",
    "        \"and remove PII Data,Bad and Curse words from content\"\n",
    "        \"then return the content without PII Data and Bad Words\"\n",
    "    ),\n",
    "    backstory = (\n",
    "        \"You are a guardrail that prevents PII Leakage and showing bad words. \"\n",
    "    ),\n",
    "    llm=crewai_hf_llm,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file_tool = FileReadTool()\n",
    "read_dir_tool = DirectoryReadTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "guard_task = Task(\n",
    "    tools = [read_dir_tool, read_file_tool, pii_tool, bad_words],\n",
    "    agent = guardrail,\n",
    "    description = (\n",
    "        \"Remove PII Data and Bad Words from any .txt file under this directory: {path}\"\n",
    "    ),\n",
    "    expected_output = (\n",
    "        \"The Result be text without any PII Data or Curse words.\"\n",
    "    ),\n",
    "    output_file=f\"../{os.getenv('OUTPUT_FILES_PATH')}/clean_text.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-23 23:43:12,530 - 2308 - __init__.py-__init__:537 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "crew = Crew(\n",
    "    agents=[guardrail],\n",
    "    tasks=[guard_task],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mGuardrail\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mRemove PII Data and Bad Words from any .txt file under this directory: ..\\assets\\data\\tmp\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mGuardrail\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mList files in directory\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"directory\\\": \\\"..\\\\\\\\assets\\\\\\\\data\\\\\\\\tmp\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "File paths: \n",
      "-..\\assets\\data\\tmp/file.txt\n",
      "- ..\\assets\\data\\tmp/foo.pdf\n",
      "- ..\\assets\\data\\tmp/Iris.csv\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mGuardrail\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mRead a file's content\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"file_path\\\": \\\"..\\\\\\\\assets\\\\\\\\data\\\\\\\\tmp/file.txt\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "can you tell me what orders i've placed in the last 3 months? my name is Hank Tate and my phone number is 555-123-4567\n",
      "motherfucker you look thirty!!\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-23 23:43:15,612 - 2308 - nlp_engine_provider.py-nlp_engine_provider:118 - WARNING: configuration file d:\\agents\\database_agent\\.venv\\lib\\site-packages\\conf\\default.yaml not found.  Using default config: {'nlp_engine_name': 'spacy', 'models': [{'lang_code': 'en', 'model_name': 'en_core_web_lg'}]}.\n",
      "2024-11-23 23:43:15,617 - 2308 - nlp_engine_provider.py-nlp_engine_provider:127 - WARNING: configuration file is missing 'ner_model_configuration'. Using default\n",
      "2024-11-23 23:43:15,623 - 2308 - ner_model_configuration.py-ner_model_configuration:78 - WARNING: model_to_presidio_entity_mapping is missing from configuration, using default\n",
      "2024-11-23 23:43:15,625 - 2308 - ner_model_configuration.py-ner_model_configuration:84 - WARNING: low_score_entity_names is missing from configuration, using default\n",
      "2024-11-23 23:43:15,627 - 2308 - ner_model_configuration.py-ner_model_configuration:89 - WARNING: labels_to_ignore is missing from configuration, using default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mGuardrail\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mPII Removal\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"text\\\": \\\"can you tell me what orders i've placed in the last 3 months? my name is Hank Tate and my phone number is 555-123-4567 motherfucker you look thirty!!\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "can you tell me what orders i've placed in <DATE_TIME>? my name is <PERSON> and my phone number is <PHONE_NUMBER> motherfucker you look thirty!!\n",
      "\n",
      "\n",
      "You ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n",
      "\n",
      "Tool Name: List files in directory\n",
      "Tool Arguments: {'directory': {'description': 'Mandatory directory to list content', 'type': 'str'}}\n",
      "Tool Description: A tool that can be used to recursively list a directory's content.\n",
      "Tool Name: Read a file's content\n",
      "Tool Arguments: {'file_path': {'description': 'Mandatory file full path to read the file', 'type': 'str'}}\n",
      "Tool Description: A tool that can be used to read a file's content.\n",
      "Tool Name: PII Removal\n",
      "Tool Arguments: {'text': {'description': 'input text.', 'type': 'str'}}\n",
      "Tool Description: Remove PII From Input Text to prevent PII Leakage.\n",
      "Tool Name: Bad Word Removal\n",
      "Tool Arguments: {'text': {'description': 'input text.', 'type': 'str'}}\n",
      "Tool Description: Remove Bad Words From Input Text .\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, only one name of [List files in directory, Read a file's content, PII Removal, Bad Word Removal], just the name, exactly as it's written.\n",
      "Action Input: the input to the action, just a simple python dictionary, enclosed in curly braces, using \" to wrap keys and values.\n",
      "Observation: the result of the action\n",
      "\n",
      "Once all necessary information is gathered:\n",
      "\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mGuardrail\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mBad Word Removal\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"text\\\": \\\"can you tell me what orders i've placed in <DATE_TIME>? my name is <PERSON> and my phone number is <PHONE_NUMBER> motherfucker you look thirty!!\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "can you tell me what orders i've placed in <DATE_TIME>? my name is <PERSON> and my phone number is <PHONE_NUMBER> **** you look thirty!!\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mGuardrail\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "can you tell me what orders i've placed in <DATE_TIME>? my name is <PERSON> and my phone number is <PHONE_NUMBER> **** you look thirty!!\u001b[00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = crew.kickoff(\n",
    "    inputs={\n",
    "        \"path\": os.path.join(os.pardir, \"assets\", \"data\", \"tmp\")\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
